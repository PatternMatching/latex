\documentclass[11pt,a4paper]{report}
\usepackage{amsmath,amsfonts,amssymb,amsthm,epsfig,epstopdf,titling,url,array}
\usepackage{enumerate}
\usepackage{parskip}

\makeatletter
\def\thm@space@setup{%
  \thm@preskip=\parskip \thm@postskip=0pt
}
\makeatother

\title{\bf Notes\\[2ex] 
       \rm\normalsize EN605.725 --- Fall 2014}
\date{\today}
\author{\bf Peter Hennings}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]

\theoremstyle{theorem}
\newtheorem{thm}{Theorem}[section]

\begin{document}
\maketitle

\chapter{Probability Theory}

\section{Set Theory}

Statistics builds on the foundation of probability theory.  Similarly,
probability theory in turn builds upon set theory.

A main objective of a statistician is to draw conclusions about a
population of objects having conducted an experiment.  The first step
in this process is identifying the possible outcomes of said
experiment.

\begin{defn}
  The set, $S$, of all possible outcomes of a particular experiment is
  called the \textit{sample space} for the experiment.
\end{defn}

We can classify sample spaces into two types: countable or
uncountable.  If the elements of a sample space can be put into a 1-1
correspondence with a subset of the integers, then the sample space is
countable.  Otherwise, it is uncountable.

\begin{defn}
  An \textit{event} is any collection of possible outcomes of an
  experiment, that is, any subset of $S$ (including $S$ itself).
\end{defn}

Let $A$ be an event, a subset of $S$.  We say that the event $A$
occurs if the outcome of the experiment is the set $A$.  When speaking
of probabilities, we generally speak of the probability of an event,
rather than a set.  But we may use the terms interchangeably.

We define formally the following two relationships, which allow us to
order and equate sets:

\begin{align*}
    & A \subset B \Leftrightarrow x \in A \Rightarrow x \in B & \textrm{(containment)} \\
    & A = B \Leftrightarrow A \subset B \textrm{ and } B \subset A & \textrm{(equality)}
\end{align*}

Given any two events (sets) $A$ and $B$, we have the following
elementary set operations:

\textbf{Union}: The union of $A$ and $B$, written $A \cup B$, is the set of elements that belong to either $A$ or $B$ or both:

\begin{align*}
    & A \cup B = \{x:x \in A \textrm{ or } x \in B\}
\end{align*}

\textbf{Intersection}: The intersection of $A$ and $B$, written $A \cap B$, is the set of elements that belong to both $A$ and $B$:

\begin{align*}
    & A \cap B = \{x:x \in A \textrm{ and } x \in B\}
\end{align*}

\textbf{Complementation}: The complement of $A$, written $A^{\complement}$, is the set of all elements that are not in A:

\begin{align*}
    & A^{\complement} = \{x:x \notin A\}
\end{align*}

\begin{thm}
For any three events, A, B, and C, defined on a sample space S,
\begin{align*}
    & A \cup B = B \cup A & \textrm{(commutativity)} \\
    & A \cap B = B \cap A \\
    & A \cup (B \cup C) = (A \cup B) \cup C & \textrm{(associativity)} \\
    & A \cap (B \cap C) = (A \cap B) \cap C \\
    & A \cap (B \cup C) = (A \cap B) \cup (A \cap C) & \textrm{(distributive laws)} \\
    & A \cup (B \cap C) = (A \cup B) \cap (A \cup C) \\
    & (A \cup B)^{\complement} = A^{\complement} \cap B^{\complement} & \textrm{(DeMorgan's Laws)} \\
    & (A \cap B)^{\complement} = A^{\complement} \cup B^{\complement}
\end{align*}
\end{thm}

\begin{defn}
  Two events $A$ and $B$ are disjoint (or mutually exclusive) if $A
  \cap B = \emptyset$.  The events $A_1, A_2, \dots$ are pairwise
  disjoint (or mutually exclusive) if $A_i \cap A_j = \emptyset$ for
  all $i \not = j$.
\end{defn}

Disjoint sets are sets with no points in common.  If we draw a Venn
diagram for two disjoint sets, the sets do not overlap.

\begin{defn}
  If $A_1, A_2, \dots$ are pairwise disjoint and $\cup_{i=0}^{\infty}
  A_i = S$, then the collection $A_1, A_2, \dots$ forms a partition of
  $S$.
\end{defn}

Partitions are very useful, allowing us to divide the sample space
into small, nonoverlapping pieces.

\section{Basics of Probability Theory}

The realization of an experiment is an outcome in the sample space.
If the experiment is performed a number of times, different outcomes
may occur each time or some outcomes may repeat.  Frequency of
occurrence is effectively probability.  More probable outcomes occur
more frequently.

\begin{defn}
A collection of subsets of $S$ is called a sigma algebra (or Borel
field), denoted by $\mathcal{B}$, if it satisfies the following three
properties:

\begin{enumerate}[(a)]
  \item $\emptyset \in \mathcal{B}$ (the empty set is an element of
    $\mathcal{B}$)
  \item If $A \in \mathcal{B}$ then $A^{\complement} \in \mathcal{B}$
    ($\mathcal{B}$ is closed under complementation)
  \item If $A_1, A_2, \dots \in \mathcal{B}$, then
    $\cup_{i=1}^{\infty} A_i \in \mathcal{B}$
\end{enumerate}

\end{defn}

The empty set $\emptyset$ is a subset of any set.  Thus, $\emptyset
\subset S$.  A sigma algebra always contains this subset.  Since $S =
\emptyset^{\complement}$, properties (a) and (b) imply that $S$ is
always in $\mathcal{B}$.  $\mathcal{B}$ is closed under countable
intersection from DeMorgan's laws.

Many different sigma algebras can be associated with a sample space
$S$.  For example, the collection of the two sets $\{\emptyset, S\}$
is usually called the trivial sigma algebra.  The only sigma algebra
we will be concerned with is the smallest one that contains all of the
open sets in a given sample space $S$.

If $S$ is finite or countable, then these technicalities do not arise,
for we define for a given sample space $S$,

\begin{align*}
  & \mathcal{B} = \{ \textrm{all subsets of S, including S itself} \}
\end{align*}

If $S$ has $n$ elements, there are $2^n$ sets in $\mathcal{B}$.  In
general, if $S$ is uncountable, it is not an easy task to describe
$\mathcal{B}$.  However, $\mathcal{B}$ is chosen to contain any set of
interest.

\begin{defn}
Given a sample space $S$ and an associated sigma algebra
$\mathcal{B}$, a probability function is a function $P$ with domain
$\mathcal{B}$ that satisfies:

\begin{enumerate}
 \item $P(A) \ge 0$ for all $A \in B$
 
 \item $P(S) = 1$

 \item If $A_1, A_2, \dots \in \mathcal{B}$ are pairwise disjoint,
   then $P\left( \cup_{i=1}^{\infty} A_i \right) = \sum_{i=1}^{\infty} P(A_i)$.
\end{enumerate}

\end{defn}

The above properties are generally referred to as the axioms of
probability (or the Kolmogorov Axioms).  Any function $P$ that
satisfies the Axioms of Probability is called a probability function.
The axiomatic definition makes no attempt to tell what particular
function $P$ to choose; it merely requires $P$ to satisfy the axioms.
For any sample space many different probability functions can be
defined.

Consider the simple experiment of tossing a fair coin, so $S = \{H,
T\}$.  By a ``fair'' coin we mean a balanced coin that is equally
likely to land on heads as it is tails ($P(\{H\}) = P(\{T\})$).  We
note the following:

\begin{align*}
  & P(\{H\}) = P(\{T\}) \\
  & P(\{H\}) + P(\{T\}) = 1 \\
  & P(\{H\}) = P(\{T\}) = 0.5
\end{align*}

\begin{thm}
  Let $S = \{s_1, \dots, s_n\}$ be a finite set.  Let $\mathcal{B}$ be
  any sigma algebra of subsets of $S$.  Let $p_1, \dots, p_n$ be
  nonnegative numbers that sum to 1.  For any $A \in \mathcal{B}$,
  define $P(A)$ by:

  \begin{align*}
    & P(A) = \sum_{\{i:s_i \in A\}} p_i
  \end{align*}

\end{thm}

\begin{proof}
We will give the proof for finite $S$.  For any $A \in \mathcal{B}$,
$P(A) = \sum_{\{i:s_i \in A\}} p_i \ge 0$, because every $p_i \ge 0$.
Thus, Axiom 1 is true.  Now,

\begin{align*}
  & P(S) = \sum_{\{i:s_i \in A\}} p_i = \sum_{i=1}^n p_i = 1
\end{align*}

Thus, Axiom 2 is true.  Let $A_1, \dots, A_k$ denote pairwise disjoint
events.  ($\mathcal{B}$ contains only a finite number of sets, so we
need consider only finite disjoint unions).  Then,

\begin{align*}
  & P \left( \bigcup_{i=1}^k A_i \right) = \sum_{\{j:s_j \in
    \cup_{i=1}^k A_i \}} p_j = \sum_{i=1}^k \sum_{\{j:s_j \in
    \cup_{i=1}^k A_i \}} p_j = \sum_{i=1}^k P(A_i)
\end{align*}

The first and third equalities are true by the definition of $P(A)$.
The disjointedness of the $A_i$'s ensures that the second equality is
true, because the same $p_j$'s appear exactly once on each side of the
equality.  Thus Axiom 3 is true and Kolmogorov's Axioms are satisfied.

\end{proof}

\subsection{The Calculus of Probabilities}

\begin{thm}
If $P$ is a probability function and $A$ is any set in $\mathcal{B}$,
then

\begin{enumerate}[(a)]

\item $P(\emptyset) = 0$, where $\emptyset$ is the empty set

\item $P(A) \le 1$

\item $P(A^{\complement}) = 1 - P(A)$

\end{enumerate}

\end{thm}

\chapter{Transformations and Expectations}

\chapter{Common Families of Distributions}

\chapter{Multiple Random Variables}

\section{Joint and Marginal Distributions}

All models covered so far have been univariate and involve only one random variable.  Models in this chapter will be multivariate and involve more than one random variable.

\begin{defn}
An n-dimensional random vector is a function from a sample space $S$ into $\mathcal{R}^n$, n-dimensional Euclidean space.  
\end{defn}

\begin{defn}
Let $(X,Y)$ be a discrete bivariate random vector.  Then the function $f(x,y)$ from $\mathcal{R}^2$ into $\mathcal{R}$ defined by $f(x,y) = P(X = x, Y = y)$ is called the joint probability mass function or joint pmf of $(X,Y)$.
\end{defn}

Continuing with our bivariate random vector $(X,Y)$, if we let $A$ be any subset of $\mathcal{R}^2$ then:

\begin{align*}
  P((X,Y) \in A) &= \sum_{(x,y) \in A} f(x,y)
\end{align*}

Since $(X,Y)$ is discrete, $f(x,y)$ is nonzero for at most a countable  number of points.  Thus, the sum is a countable sum even if $A$ is an uncountable set.

\begin{defn}
  A function $f(x,y)$ from $\mathcal{R}^2$ into $\mathcal{R}$ is called a joint probability density function or joint pdf of the continuous bivariate random vector $(X,Y)$ if, for every $A \in \mathcal{R}^2$:

  \begin{align*}
    P((X,Y) \in A) = \int_A \int f(x,y) dx dy
  \end{align*}
\end{defn}

\section{Conditional Distributions and Independence}

Often times, when we observe the value of two or more random variables, the values observed are related.  For example, a person's height and weight are obviously dependent.  Conditional probabilities regarding one variable given knowledge of another variable can be computed using the join distribution of $(X,Y)$.

\begin{defn}
  Let $(X,Y)$ be a discrete bivariate random vector with joint pmf $f(x,y)$ and marginal pmfs $f_X(x)$ and $f_Y(y)$.  For any $x$ such that $P(X = x) = f_X(x) > 0$, the conditional pmf of $Y$ given that $X = x$ is the function of $y$ denoted by $f(y|x)$ and defined by:

  \begin{align*}
    f(y|x) &= P(Y = y \, | \, X = x) = \frac{f(x,y)}{f_X(x)}
  \end{align*}

For any $y$ such that $P(Y = y) = f_Y(y) > 0$, the conditional pmf of $X$ given that $Y = y$ is the function of $x$ denoted by $f(x|y)$ and defined by:

\begin{align*}
  f(x|y) &= P(X = x \, | \, Y = y) = \frac{f(x,y)}{f_Y(y)}
\end{align*}

\end{defn}

\begin{defn}
Let $(X,Y)$ be a continuous bivariate random vector with joint pdf $f(x,y)$ and marginal pdfs $f_X(x)$ and $f_Y(y)$.  For any $x$ such that $f_X(x) > 0$, the conditional pdf of $Y$ given that $X = x$ is the function of $y$ denoted by $f(y|x)$ and defined by:

\begin{align*}
  f(y|x) &= \frac{f(x,y)}{f_X(x)}
\end{align*}

\end{defn}

The conditional pmf's can also be used to calculate expected values.  IF $g(Y)$ is a function of $Y$, then the conditional expected value of $g(Y)$ given that $X = x$ is denoted $\mathrm{E}\left[g(Y) \, | \, x \right]$ and is given by:

\begin{align*}
  \mathrm{E}\left[g(Y) \, | \, x \right] &= \sum_y g(y) f(y|x) \\
  \mathrm{E}\left[g(Y) \, | \, x \right] &- \int_y g(y) f(y|x) dy
\end{align*}

The variance of the probability distribution described by $f(y|x)$ is called the conditional variance of $Y$ given $X = x$.  Using the notation $Var(Y \, | \, x)$ for this, we have, using the oridinary definition of variance,

\begin{align*}
  \mathrm{Var}(Y \, | \, x) &= \mathrm{E}(Y^2 \, | \, x) - (\mathrm{E}(Y \, | \, x))^2
\end{align*}

\begin{defn}
  Let $(X, Y)$ be a bivariate random vector with joint pdf or pmf $f(x,y)$ and marginal pdfs or pmfs $f_X(x)$ and $f_Y(y)$.  Then $X$ and $Y$ are called independent random variables if, for every $x \in \mathcal{R}$ and $y \in \mathcal{R}$,

  \begin{align*}
    f(x,y) &= f_X(x) f_Y(y)
  \end{align*}

  If $X$ and $Y$ are independent, the conditional pdf of $Y$ given $X = x$ is:

  \begin{align*}
    f(y|x) &= \frac{f(x,y)}{f_X(x)} \\
    &= \frac{f_X(x) f_Y(y)}{f_X(x)} \\
    &= f_Y(y)
  \end{align*}

  regardless of the value of $x$.
\end{defn}

\begin{thm}
  Let $(X,Y)$ be a bivariate random vector with joint pdf or pmf $f(x,y)$.  Then $X$ and $Y$ are independent random variables if and only if there exists $g(x)$ and $h(y)$ such that, for every $x \in \mathcal{R}$ and $y \in \mathcal{R}$:
\end{thm}

\end{document}
